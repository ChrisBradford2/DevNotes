# L'int√©gration et la livraison continues avec la d√©marche DevOps

## Qu'est-ce que l'int√©gration continue ?

> **L'int√©gration et la livraison continues**, ou en anglais _**Continuous Integration and Continuous Delivery (CI/CD)**_ permettent de :
> - **acc√©l√©rer le _Time-to-Market_** (le temps de d√©veloppement et de mise en production d'une fonctionnalit√©) ;
> - **r√©duire les erreurs** lors des livraisons ;
> - assurer une **continuit√© de service** des applications.

**L'int√©gration continue** est un ensemble de pratiques utilis√©es en g√©nie logiciel, consistant √† v√©rifier, √† chaque modification de code source que le r√©sultat des modifications ne produit pas de r√©gression dans l'application d√©velopp√©e.

Le principe de l'int√©gration continue est justement de d√©tecter ces probl√®mes d'int√©gration au plus t√¥t dans le cycle de d√©veloppement.

> L'int√©gration continue va se faire en 5 √©tapes :
> 1. Planifiez votre d√©veloppement.
> 2. Compilez et int√©grez votre code.
> 3. Testez votre code.
> 4. Mesurez la qualit√© de votre code.
> 5. G√©rez les livrables de votre application.

Toutes les √©tapes se feront sur GitLab. Les √©tapes 2 √† 4 seront lanc√©es automatiquement gr√¢ce √† GitLab CI :

![√âtapes de l'int√©gration continue sur GitLab](https://user.oc-static.com/upload/2019/05/23/15586109893555_1c3_illus_WHITEBG%20%280-00-17-23%29_4.png)

### √âtape 1 : Planifiez votre d√©veloppement

Afin de **savoir quoi d√©velopper**, il est n√©cessaire d'avoir √† disposition un outil permettant la collaboration entre les d√©veloppeurs. Cet outil permettra notamment de g√©rer les diff√©rentes releases et toutes les fonctionnalit√©s, de garantir la priorit√© du backlog, etc.

Intervenant tout au long du projet, la collaboration de toute l'√©quipe est n√©cessaire pour assurer la planification du projet. Cette planification est √©troitement li√©e √† la m√©thodologie Scrum. Elle a pour but de d√©couper le projet en petites t√¢ches √† r√©aliser par toute l'√©quipe.

> Pour collaborer avec vos √©quipes, vous pourrez utiliser **Jira**, **GitLab**, **Confluence**, **ALM Octane** ou encore **Pivotal Tracker**.

### √âtape 2 : Compilez et int√©grez votre code

#### Le contr√¥le de code source

Le code source se doit d'√™tre disponible √† chaque instant sur un d√©p√¥t central. Chaque d√©veloppement doit faire l'objet d'un suivi de r√©vision. Le code doit √™tre compilable √† partir d'une r√©cup√©ration fra√Æche, et ne faire l'objet d'aucune d√©pendance externe. M√™me s'il existe des notions de branche, la cr√©ation d'une branche doit √™tre √©vit√©e le plus possible, privil√©giant le d√©veloppement sur la branche principale ; cela √©vite de maintenir plusieurs versions en parall√®le. Ce genre de pratique est appel√© *trunk-based development*.

> Pour faire du contr√¥le de source, vous retrouverez les outils **Git**, **Subversion**, **GitHub**, **GitLab**, **Perforce** ou bien **Bitbucket**.

#### L'orchestrateur

Ensuite, toutes les √©tapes doivent √™tre automatis√©es par un **orchestrateur**, qui saura reproduire ces √©tapes et g√©rer les d√©pendances entre elles. De plus, l'utilisation d'un orchestrateur permet de donner acc√®s √† tous, et √† tout moment, √† un tableau de bord qui donnera l'√©tat de sant√© des √©tapes d'int√©gration continue. Ainsi, les d√©veloppeurs ont au plus t√¥t la boucle de feedback n√©cessaire, afin de garantir que l'application soit pr√™te √† tout moment. De plus, l'orchestrateur permettra d'aller plus loin dans la livraison continue.

> L'orchestration des √©tapes de votre int√©gration continue peut se faire gr√¢ce √† des outils comme **Jenkins**, **TeamCity**, **Azure DevOps**, **GitLab CI**, **Concours CI**, **Travis CI** ou **Bamboo**.

La premi√®re √©tape, et celle qui para√Æt la plus √©vidente, est de compiler le code de mani√®re continue. En effet, sans cette √©tape, le code est compil√© manuellement sur le poste du d√©veloppeur, afin que ce dernier s'assure que son code compile.

Malheureusement, comme dit pr√©c√©demment, le d√©veloppeur ne s'assure pas que son code permet de bien compiler avec tous les autres d√©veloppements faits par l'√©quipe. √Ä la prochaine livraison, un d√©veloppeur int√®gre alors manuellement toutes les modifications, une op√©ration qui produit beaucoup de peine et de souffrance.

La mise en place d'une premi√®re √©tape de compilation dans un processus d'int√©gration continue permet justement de ne plus se soucier si des modifications de code cassent la compilation. Le d√©veloppeur doit alors s'assurer de bien envoyer son code source sur le d√©p√¥t central. En faisant cela, il d√©clenche une premi√®re √©tape de compilation, avec toutes les modifications des autres d√©veloppeurs. Si la compilation ne se fait pas, le code est alors rejet√©, et le d√©veloppeur doit corriger ses erreurs.

Apr√®s cette premi√®re √©tape, le code devient plus s√ªr, et le d√©p√¥t de code source garantit qu'√† chaque instant, un d√©veloppeur r√©cup√®re un code qui compile. Dans cette √©tape, les tests ne sont pas encore ex√©cut√©s. Le code peut donc √™tre de mauvaise qualit√©.

> Vous pourrez compiler votre code avec **Maven**, **Ant**, **Gradle**, **MSBuild**, **NAnt**, **Gulp** ou encore **Grunt**.

### √âtape 3 : Testez votre code

#### Les tests unitaires

Dans cette √©tape, **l'orchestrateur se charge de lancer les tests unitaires √† la suite de la compilation**. Ces tests unitaires, g√©n√©ralement avec un framework associ√©, garantissent que le code respecte un certain niveau de qualit√©.

> Les tests unitaires permettent de v√©rifier le bon fonctionnement d'une partie pr√©cise d'un logiciel ou d'une portion d'un programme.

Plus il y a de tests unitaires, plus le code est garanti s√ªr. √âvidemment, l'orchestrateur ne peut lancer que les tests qui ont √©t√© cod√©s par les d√©veloppeurs, et ne peut pas inventer de nouveaux cas de tests.

Ces tests doivent s'ex√©cuter **de la mani√®re la plus rapide possible**, afin d'avoir un feedback le plus rapide lui aussi. Pour arriver √† ce niveau, **il est n√©cessaire que les tests unitaires n'aient aucune d√©pendance** vis-√†-vis de syst√®mes externes, comme par exemple une base de donn√©es, ou m√™me le syst√®me de fichiers de la machine.

Les tests unitaires apportent 3 atouts √† la production :
- **trouver les erreurs plus facilement**. Les tests sont ex√©cut√©s durant tout le d√©veloppement, permettant de visualiser si le code fra√Æchement √©crit correspond au besoin ;
- **s√©curiser la maintenance**. Lors d'une modification d'un programme, les tests unitaires signalent les √©ventuelles r√©gressions. En effet, certains tests peuvent √©chouer √† la suite d'une modification, il faut donc soit r√©√©crire le test pour le faire correspondre aux nouvelles attentes, soit corriger l'erreur se situant dans le code ;
- **documenter le code**. Les tests unitaires peuvent servir de compl√©ment √† la documentation ; il est tr√®s utile de lire les tests pour comprendre comment s'utilise une m√©thode. De plus, il est possible que la documentation ne soit plus √† jour, mais les tests, eux, correspondent √† la r√©alit√© de l'application.

**L'ensemble des tests unitaires doivent √™tre relanc√©s apr√®s une modification** du code, afin de v√©rifier qu'il n'y ait pas de r√©gressions (l'apparition de nouveaux dysfonctionnements). 

La multiplicit√© des test unitaires oblige √† les **maintenir** dans le temps, au fur et √† mesure que le d√©veloppement avance.

> Pour impl√©menter et ex√©cuter vos tests unitaires, vous retrouverez des outils comme **JUnit**, **NUnit** ou encore **XUnit**.

### √âtape 4 : Mesurez la qualit√© de votre code

Maintenant que les tests unitaires sont √©crits et ex√©cut√©s, nous commen√ßons √† avoir une meilleure qualit√© de code, et √† √™tre rassur√©s sur la fiabilit√© et la robustesse de l'application. Gr√¢ce √† la compilation et aux tests unitaires, nous pouvons maintenant **mesurer la qualit√© du code**. Tout ceci permet aux d√©veloppeurs de **maintenir** dans le temps un code de tr√®s bonne qualit√©, alertant l'√©quipe en cas de d√©rive des bonnes pratiques de tests.

> L'√©tape de qualit√© de code est diff√©rente de l'√©tape de test, car cette √©tape de **qualit√©** assure que le code sera **maintenable** et **√©volutif** au fur et √† mesure de son cycle de vie, alors que les **tests** servent √† garantir que le code **impl√©mente bien les fonctionnalit√©s** demand√©es, et ne contient pas (ou peu) de **bugs**.

Lors de l'√©tape de qualit√© de code, nous cherchons √† assurer la plus petite **dette technique** possible de notre application. La dette technique est le temps n√©cessaire √† la correction de bugs ou √† l'ajout de nouvelles fonctionnalit√©s, lorsque nous ne respectons pas les r√®gles de coding. La dette est exprim√©e en **heures de correction**. Plus cette dette est √©lev√©e, plus le code sera difficile √† maintenir et √† faire √©voluer.

L'√©tape de qualit√© de code mesure aussi d'autres m√©triques, comme le nombre de vuln√©rabilit√©s au sein du code, la couverture de test, mais aussi les [*code smells*](https://fr.wikipedia.org/wiki/Code_smell) (qui sont des mauvaises pratiques √† ne pas impl√©menter), la [complexit√© cyclomatique](https://fr.wikipedia.org/wiki/Nombre_cyclomatique) (complexit√© du code applicatif) ou la duplication de code. C'est le r√¥le du d√©veloppeur de respecter les normes d√©finies et de corriger au fur et √† mesure son code.

Afin de renforcer la qualit√© du code et de ne pas autoriser le d√©ploiement d'un code de mauvaise qualit√©, nous pouvons impl√©menter un **arr√™t complet du pipeline d'int√©gration continue, si le code n'atteint pas la qualit√© requise**.

> **Les outils** : la qualit√© du code peut √™tre √©valu√©e gr√¢ce √† **SonarQube**, **Cast** ou **GitLab Code Quality**.

### √âtape 5 : G√©rez les livrables de votre application

Le code, une fois compil√©, doit √™tre d√©ploy√© dans un d√©p√¥t de livrables, et versionn√©. Les binaires produits sont appel√©s **_artefacts_**. Ces artefacts doivent √™tre accessibles √† toutes les parties prenantes de l'application, afin de pouvoir les d√©ployer et lancer les tests autres qu'unitaires (test de performance, test de bout en bout, etc.). Ces artefacts sont disponibles dans un stockage, centralis√© et organis√©, de donn√©es. Ce peut √™tre une ou plusieurs bases de donn√©es o√π les artefacts sont localis√©s en vue de leur distribution sur le r√©seau, ou bien un endroit directement accessible aux utilisateurs.

> La mise √† disposition des artefacts peut √™tre faite par **Nexus**, **Artifactory**, **GitLab repository**, **Quay**, **Docker Hub**.

### Utilisez GitLab pour mettre en place un pipeline CI/CD

Dans la suite de ce cours, nous ferons le choix de GitLab. Cet outil a l'avantage d'avoir toutes les briques n√©cessaires √† la mise en place de l'int√©gration continue, sans rentrer dans des √©tapes complexes de mise en place des outils, ainsi que les connexions associ√©es.

Afin de pouvoir illustrer l'int√©gration continue, nous allons travailler sur un projet open source : la mise en place du site web d'une clinique v√©t√©rinaire via Spring Boot. Toutes les √©tapes de mise en place de l'int√©gration continue seront enti√®rement d√©taill√©es dans la suite de cette partie.

> Vous n'avez pas besoin de conna√Ætre Spring Boot, ni d'√™tre cal√© en d√©veloppement Java. Tout le code vous sera fourni, vous lui ferez passer toutes les √©tapes du pipeline CI/CD.

## Planifiez votre d√©veloppement

> La m√©thodologie DevOps emprunte de nombreux concepts √† **Scrum**. Afin de bien suivre la suite de ce chapitre, il vous sera donc n√©cessaire d'avoir des connaissances du vocabulaire et de la m√©thodologie Scrum. Il vous faudra notamment conna√Ætre les termes *epic*, *user story*, *task*, *bug*, *sprint*, *Product Backlog*, *board*,*burndown chart*, *Definition of Done*, *Definition of Ready*, tels que d√©finis par la m√©thodologie Scrum.

Dans GitLab, l'**issue** est la notion centrale pour d√©finir n'importe quoi : que ce soit une epic, une feature ou m√™me un bug. La distinction se fait via des labels, que l'on positionne sur l'issue.

Il est temps de d√©finir notre premier **backlog**, c'est-√†-dire l'ensemble des t√¢ches √† r√©aliser sur notre projet.

### Cr√©ez votre projet GitLab

Dans un premier temps, nous allons **cr√©er un projet dans GitLab**. Pour cela, nous allons utiliser la plateforme [https://gitlab.com/](https://gitlab.com/), afin d'√©viter d'installer notre propre plateforme GitLab en local.

Si vous n'avez pas encore de compte sur GitLab, je vous invite √† vous en cr√©er un, puis √† vous connecter.

Une fois connect√©, vous arrivez sur une page listant tous vos projets. Si vous venez de cr√©er le compte, normalement cette page sera vide.

> Comme expliqu√© dans le premier chapitre, nous allons nous baser sur le projet **PetClinic** tout au long du cours. Dans ce chapitre, nous allons commencer √† planifier le d√©veloppement de fonctionnalit√©s pour ce projet.

Pour **cr√©er un nouveau projet dans GitLab**, une fois connect√©, cliquez sur le bouton `New Project`. Sur la nouvelle page, il faut entrer un nouveau nom de projet. Dans le champ Project Name, nous allons entrer le nom **spring-petclinic-microservices**. Notez au passage que GitLab remplit automatiquement le champ Project Slug. Il est imp√©ratif de passer le projet en **Public** afin de b√©n√©ficier de toutes les fonctionnalit√©s abord√©es dans ce cours. Une fois tous les champs remplis, l'√©cran devrait ressembler √† cela :

![Cr√©ation d'un projet sur Gitlab](https://user.oc-static.com/upload/2019/05/23/15586242595092_new-project-detail.png)

Appuyez maintenant sur le bouton *Create Project*. Vous arrivez alors sur la page du projet fra√Æchement cr√©√©. Avant de r√©cup√©rer le code source de l'application, et de l'int√©grer dans GitLab, nous allons mettre en place les diff√©rentes briques n√©cessaires au bon d√©roulement du projet. Tout d'abord, nous allons naviguer dans la partie Issues, afin d'ajouter les colonnes n√©cessaires √† notre projet. Pour ce faire, il suffit d'aller sur le menu √† gauche, survoler le menu Issues, et cliquer sur le lien Boards. Sur cette page, GitLab nous propose d'ajouter les listes par d√©faut via le bouton Add default lists. GitLab cr√©e alors deux nouvelles colonnes, To Do et Doing :

![Votre board sur GitLab](https://user.oc-static.com/upload/2019/05/23/15586243172078_boards-new.png)

Ce **board** sera notre board par d√©faut durant tout notre projet, afin de voir son avancement. Nous allons ensuite **cr√©er les diff√©rents labels** que nous avons vus pr√©c√©demment, afin de pouvoir cr√©er et cat√©goriser les issues que nous allons ouvrir. Pour ce faire, nous allons aller dans le sous-menu Labels du menu Issues. Sur la nouvelle page, il faut alors cliquer sur le bouton **New Label** pour cr√©er une nouvelle cat√©gorie d'issue. Notez que GitLab a d√©j√† cr√©√© les deux labels To Do et Doing pour nous.

Sur la page de cr√©ation de nouveaux labels, nous allons ajouter tous les labels n√©cessaires √† la cat√©gorisation des issues :

![Cr√©ation d'un nouveau label](https://user.oc-static.com/upload/2019/05/23/15586244055298_label-new.png)

> **Les cat√©gories √† cr√©er sont** : Epic, User Story, Bug, Ready, Rejected, High, Medium, Low, In Review. Une fois les labels cr√©√©s, la liste devrait ressembler √† ceci :

![Tous vos labels sont pr√™ts !](https://user.oc-static.com/upload/2019/05/23/15586244563257_labels-list.png)

Vous noterez la cr√©ation de plusieurs labels que je n'ai pas d√©taill√©s : High, Medium, Low, Ready, Rejected et In Review. Ces labels sont utilis√©s pour cat√©goriser plusieurs issues et pour cr√©er un nouveau board, que nous allons appeler **Product Backlog**. Pour ce faire, il faut retourner dans le menu Board. Tout d'abord, dans la page courante, cliquez sur Add List et s√©lectionnez le label In Review pour ajouter une nouvelle colonne dans le board courant. Le nouveau board doit ressembler √† cela (pour des questions de lisibilit√©, j'ai repli√© les colonnes Open et Closed dans la capture d'√©cran suivante) :

![Nouvelle colonne sur votre board de d√©veloppement](https://user.oc-static.com/upload/2019/05/23/15586245146433_development-board.png)

Ensuite, sur la page, en haut √† gauche, il y a une liste d√©roulante contenant tous les boards cr√©√©s. Pour l'instant, il n'y en a qu'un seul, celui de d√©veloppement qui est actuellement affich√©.

Dans cette liste d√©roulante, s√©lectionnez **Create New Board**, puis donnez-lui le nom de **Product**. Ce board sera notre **Product Backlog** qui listera toutes les epics, ainsi que les user stories associ√©es et leurs √©tats respectifs :

![Cr√©ez votre Product Backlog](https://user.oc-static.com/upload/2019/05/23/1558624642716_new-board.png)

Sur la nouvelle page, apr√®s avoir cliqu√© sur le bouton Create Board, il faut maintenant ajouter les colonnes Low, Medium, High et Rejected afin de pouvoir classifier les epics sur ce board. Pour ce faire, il faut cliquer sur la liste d√©roulante Add List, et ajouter les labels correspondants.

Votre board devrait ressembler maintenant √† cela :

![Votre Product Backlog](https://user.oc-static.com/upload/2019/05/23/15586246843437_product-board-detail.png)

Nous avons maintenant tous les outils n√©cessaires afin de commencer notre travail sur le projet. Le workflow de d√©veloppement se d√©roule comme suit :

1. Le product owner travaille avec les utilisateurs finaux afin de d√©finir un **Product Backlog**. Ce Product Backlog est constitu√© de diff√©rentes **epics**.
2. Ces **epics** doivent faire appara√Ætre plusieurs crit√®res, comme par exemple des wireframes ou autres √©crans d√©finissant l'application. Une epic en high passe en sprint backlog lorsque son p√©rim√®tre est d√©limit√© avec un label **Ready**, et le d√©veloppement est confirm√© avec le client. Ce n‚Äôest qu‚Äô√† ce moment que l‚Äôepic est discut√©e avec l‚Äô√©quipe et d√©compos√©e en user stories, d√©crivant la feature √† d√©velopper.
3. Les **user stories** doivent respecter la Definition of Ready d√©finie plus t√¥t, lors du cycle de d√©veloppement. Une user story n'est ready que si elle a bien √©t√© √©crite, et contient tous les √©l√©ments n√©cessaires √† son d√©veloppement durant le sprint.
4. Une fois que le sprint backlog a √©t√© d√©compos√© en user stories, nous pouvons alors commencer la planification du sprint backlog.

Pour ce cours, nous allons cr√©er **deux issues** :
- **une epic** ;
- **une user story**.

### Cr√©ez votre premi√®re epic

Pour cr√©er une **epic**, le plus simple est d'aller dans le sous-menu List du menu Issues, et de cliquer sur le bouton **New Issue**.

Sur la nouvelle page, il faut alors renseigner les champs n√©cessaires. Commen√ßons par renseigner le titre, ainsi que la description de l'issue :

**Titre de l'issue :**

```
[EPIC] Gestion des v√©t√©rinaires
```

**Description de l'issue :**

```
Dans le projet *PetClinic*, il faut ajouter la gestion des v√©t√©rinaires.
Impl√©mentation de :
- Cr√©ation des v√©t√©rinaires
- Recherche des v√©t√©rinaires
- Mise √† jour des v√©t√©rinaires
- Suppression des v√©t√©rinaires

T√¢ches √† faire :
- [x] Cr√©ation des v√©t√©rinaires
- [x] Recherche des v√©t√©rinaires
- [x] Mise √† jour des v√©t√©rinaires
- [ ] Suppression des v√©t√©rinaires
- [ ] Supprimer les v√©t√©rinaires
- [x] Suppression de la base de donn√©es
```

Ajoutez-lui le label Epic :

![Cr√©ez votre premi√®re epic](https://user.oc-static.com/upload/2019/05/23/15586247348176_new-epic.png)

Et enregistrez en cliquant sur le bouton Submit Issue.

### Cr√©ez votre premi√®re user story

La deuxi√®me issue sera de type user story. Ajoutez une nouvelle issue en cliquant sur le bouton New Issue :

**Titre de l'issue :**

```
[User story] Suppression du v√©t√©rinaire
```

**Description de l'issue :**

```
En tant qu'administrateur, je dois pouvoir supprimer un v√©t√©rinaire afin que celui-ci ne s'affiche plus dans l'application
```

Et enregistrez-la.

Si vous revenez sur la liste des issues, vous avez maintenant deux issues cr√©√©es :

![Vos 2 issues cr√©√©es](https://user.oc-static.com/upload/2019/05/23/15586248070332_list-issues.png)

### Organisez votre backlog

Nous allons maintenant **associer la user story** fra√Æchement cr√©√©e √† l'epic que l'on a cr√©√©e auparavant. Pour ce faire, il suffit d'aller sur la description de l'epic, de cliquer sur le bouton +, au niveau du menu Related Issues, d'ajouter le num√©ro de la user story (dans mon cas, #5), et de cliquer sur Add.

Si nous retournons maintenant sur le menu Boards, nous allons voir que sur les deux boards cr√©√©s (Development et Product), dans la partie Open, nous avons nos deux issues cr√©√©es pr√©c√©demment :

![Votre user story associ√©e √† votre epic](https://user.oc-static.com/upload/2019/05/23/15586248607207_board-not-filtered.png)

Cependant, nous ne voulons voir ici que les issues associ√©es √† chacun des boards (user stories pour le board Development, et epic pour le board Product). Pour ce faire, il suffit de cliquer sur le bouton Edit Board, et d'ajouter uniquement les labels qui nous int√©ressent :

![Configurez vos boards](https://user.oc-static.com/upload/2019/05/23/15586249458233_edit-board-development.png)

En modifiant les boards, nous nous retrouvons bien avec les issues qui nous int√©ressent sur chacun des boards.

En d√©pla√ßant nos issues sur chacun des boards, nous pouvons jouer sur la priorisation des epics, ou l'avancement des user stories.

![Priorisez vos epics](https://user.oc-static.com/upload/2019/05/23/15586250482371_priorizing-product.png)

La derni√®re chose √† faire est de cr√©er un sprint, et de voir le burndown chart associ√©. Pour ce faire, il faut aller dans le menu Milestones, et cliquer sur le bouton New Milestone.

Ensuite, il suffit de remplir les informations du sprint, et de cliquer sur le bouton Create Milestone :

![Cr√©ez une milestone](https://user.oc-static.com/upload/2019/05/23/15586251686628_new-milestone-detail.png)

Nous avons maintenant acc√®s au burndown chart du sprint en cours :

![Votre burndown chart](https://user.oc-static.com/upload/2019/05/23/15586252007218_burndown-chart.png)

Afin **d'associer des issues au sprint en cours**, il suffit d'aller sur chacune des issues que l'on souhaite associer au sprint, et de modifier leur propri√©t√© sur le menu √† droite. Dans cet exemple, j'ai modifi√© le milestone, le time tracking (en commentant l'issue avec les commandes /estimate et /spend), la due date, le weight, et je me suis assign√© l'issue :

![Timeline d'√©volution des boards](https://user.oc-static.com/upload/2019/05/23/15586252464075_edit-issue.png)

Dor√©navant, toute l'√©quipe pourra suivre l'avancement du burndown chart facilement :

![Burndown chart accessible √† toute l'√©quipe !](https://user.oc-static.com/upload/2019/05/23/15586252982251_burndown-chart-complete.png)

## Int√©grez votre code en continu

### Clonez le projet sur votre poste

Pour pouvoir commencer √† travailler sur le projet, afin de r√©cup√©rer le code source, nous allons dans un premier temps **cloner le repository Git**. Pour ce faire, retournez sur la **page d'accueil du projet** o√π se trouvent toutes les instructions n√©cessaires au clonage du projet.

Cliquez en haut √† droite sur le bouton bleu **Clone**, et copiez la deuxi√®me ligne de la pop-up **Clone with HTTPS**.

Prenez ensuite une console d'ordinateur, repr√©sentant votre poste de d√©veloppeur, et clonez le repository en tapant la commande suivante :

```
git clone https://gitlab.com/[votre-nom-d-utilisateur]/spring-petclinic-microservices.git
cd spring-petclinic-microservices
```

Une fois le clone fait, nous nous retrouvons avec un dossier vide o√π la branche `master` est associ√©e √† notre repository GitLab. Nous allons **ajouter une branche** `upstream` sur GitHub et puller les derni√®res modifications GitHub. Les commandes √† taper sont les suivantes :

```
git remote add upstream https://github.com/spring-petclinic/spring-petclinic-microservices.git
git pull upstream master
git push origin master
```

Normalement, si les commandes pr√©c√©dentes ont √©t√© ex√©cut√©es, le dossier Git devrait contenir le code source du projet PetClinic, ainsi que toutes les modifications associ√©es.

![Votre projet GitLab une fois le code clon√©](https://user.oc-static.com/upload/2019/05/27/15589768409364_gitlab.png)

### Activez l'int√©gration continue sur votre projet avec GitLab

Nous allons maintenant ajouter un **pipeline d'int√©gration continue**, afin d'impl√©menter les diff√©rentes √©tapes que nous avons vues pr√©c√©demment. Les √©tapes de ce pipeline seront lanc√©es successivement, lors de chaque nouveau push du code sur le repo. Voici √† quoi ressemblera le pipeline :

![Les √©tapes que nous allons mettre en place](https://user.oc-static.com/upload/2019/05/29/15591251962731_1c3_illus_WHITEBG%20%280-00-17-23%29_0.png)

Pour **activer l'int√©gration continue sur GitLab**, le plus simple est de cliquer sur le bouton Set up CI/CD sur la page d'accueil du projet. Cette commande va cr√©er le fichier `gitlab-ci.yml` dans votre projet. C'est sur ce fichier que vous d√©crirez tout votre pipeline CI/CD avec la syntaxe YAML.

Et d'ajouter les lignes suivantes dans le fichier :
```yml
stages:
  - build
  - test

cache:
  paths:
    - .m2/repository
  key: "$CI_JOB_NAME"

build_job:
  stage: build
  script:
    - ./mvnw compile
      -Dhttps.protocols=TLSv1.2
      -Dmaven.repo.local=$CI_PROJECT_DIR/.m2/repository
      -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=WARN
      -Dorg.slf4j.simpleLogger.showDateTime=true
      -Djava.awt.headless=true
      --batch-mode --errors --fail-at-end --show-version -DinstallAtEnd=true -DdeployAtEnd=true
  image: openjdk:8-alpine

test_job:
  stage: test
  script:
    - ./mvnw test
      -Dhttps.protocols=TLSv1.2
      -Dmaven.repo.local=$CI_PROJECT_DIR/.m2/repository
      -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=WARN
      -Dorg.slf4j.simpleLogger.showDateTime=true
      -Djava.awt.headless=true
      --batch-mode --errors --fail-at-end --show-version -DinstallAtEnd=true -DdeployAtEnd=true
  image: openjdk:8-alpine
```

Ce fichier est la pierre angulaire de l'impl√©mentation d'un pipeline dans GitLab. Ce fichier s'appelle `.gitlab-ci.yml`, et c'est ici que nous allons d√©finir notre pipeline. Dans cet exemple, nous avons impl√©ment√© **deux √©tapes** :
- l'√©tape de compilation avec la t√¢che `build_job` ;
- l'√©tape des tests avec la t√¢che `test_job`.

**D√©couvrons le fichier bloc par bloc !**

#### D√©finissez les √©tapes du pipeline

Dans un premier temps, je d√©finis les **√©tapes** de mon pipeline avec le mot cl√© `stages`. Ce mot cl√© permet de d√©finir l'ordre des √©tapes. Ici, la premi√®re √©tape va √™tre le `build`, et ensuite les `tests`. 

√áa veut dire que les **t√¢ches** (ou *jobs* en anglais) associ√©es √† **l'√©tape** `build` (ici `build_job`) vont s'ex√©cuter en premier, puis les t√¢ches de l'√©tape `test` (ici `test_job`).

#### Acc√©l√©rez les √©tapes avec le cache

Le deuxi√®me bloc, avec le mot cl√© `cache`, est ici utilis√© pour acc√©l√©rer toutes nos √©tapes. Effectivement, dans le cas d'une compilation Java avec Maven (notre cas), cette compilation r√©cup√®re beaucoup de d√©pendances et de librairies externes. Ces librairies sont stock√©es dans le r√©pertoire `.m2`.

Gr√¢ce √† l'utilisation du mot cl√© `cache` et de la variable pr√©d√©finie de GitLab `$CI_JOB_NAME`, ce r√©pertoire est commun √† tous les jobs du pipeline.

#### D√©finissez les jobs √† effectuer

Ensuite, je d√©clare deux jobs, correspondant chacun √† une des √©tapes de notre pipeline d'int√©gration continue. Dans ces deux jobs, nous voyons que nous avons trois diff√©rentes lignes. D√©couvrons √† quoi ces lignes correspondent :
- `stage` : c'est le nom de l'√©tape qui va appara√Ætre dans notre pipeline d'int√©gration continue. Cela correspond aussi au `stage` auquel sera ex√©cut√© le job ;
- `script` : ce sont les lignes de script √† lancer afin d'ex√©cuter l'√©tape. Ici, nous lan√ßons le script Maven suivant son lifecycle. Dans la partie - `build`, nous lan√ßons la compilation ; et dans la partie `test`, nous lan√ßons les tests de l'application. D'autres options sont d√©finies afin d'acc√©l√©rer le temps de traitement de ces lignes. Le `script` va alors t√©l√©charger Maven, l‚Äôoutil de compilation, toutes les d√©pendances de l‚Äôapplication, et lancer la compilation du projet ;
- `image` : c'est l'image Docker qui va √™tre lanc√©e par GitLab afin d'ex√©cuter les lignes de script que nous avons d√©finies. Ici, l'image `openjdk:8-alpine`, qui contient d√©j√† Java 8, va √™tre lanc√©e afin de pouvoir compiler le projet. Une fois le fichier sauvegard√©, le pipeline de build se lance, et vous devriez voir les diff√©rentes √©tapes se lancer (ici, l'√©tape de build et l'√©tape de test).

Lors de l'√©tape de `test`, le pipeline va ex√©cuter les tests unitaires d√©j√† pr√©sents au sein du projet. L'objectif de cette √©tape est de s'assurer de lancer les tests √©crits par les d√©veloppeurs. **Si un seul de ces tests √©choue, le pipeline s'arr√™te**.

### Lancez votre pipeline CI/CD

Pour voir le pipeline complet, il suffit de cliquer sur le sous-menu Pipelines dans le menu CI/CD.

![La page Pipeline avec toutes les ex√©cutions du pipeline](https://user.oc-static.com/upload/2019/05/27/15589772375269_pipeline.png)

En cliquant sur le statut *running* du pipeline, nous avons plus de d√©tails sur ce pipeline, les jobs associ√©s ainsi que leurs statuts.

![D√©tail d'ex√©cution du pipeline](https://user.oc-static.com/upload/2019/05/27/15589773076171_pipeline-detail.png)

### Et si l'application contient un bug ?

#### Lancez votre pipeline avec un bug

> Afin de d√©montrer un workflow typique de CI/CD, nous allons **introduire un bug dans l'application**. üêõ Ainsi, nous verrons comment le pipeline de CI/CD le d√©tecte, et le corrige. Dans un premier temps, nous allons r√©cup√©rer le fichier que nous venons de cr√©er :

```
git pull
```

Le dossier courant devrait avoir le nouveau fichier `.gitlab-ci.yml`. Nous allons √©diter un fichier afin d'introduire un bug. Dans un premier temps, cr√©ez une nouvelle branche qui va accueillir nos modifications :

```
git checkout -b refactor-customers
```

Ensuite, **√©ditez le fichier** Java "*spring-petclinic-customers-service/src/main/java/org/springframework/samples/petclinic/customers/CustomersServiceApplication.java*" Supprimez par exemple le " **;** " situ√© √† la fin de la ligne `package org.springframework.samples.petclinic.customers` et commitez les changements dans Git :
```
git add spring-petclinic-customers-service/src/main/java/org/springframework/samples/petclinic/customers/CustomersServiceApplication.java
git commit -m "Refactorisation du code des clients"
git push origin refactor-customers
```

Vous devriez maintenant avoir deux branches visibles sur la page d'accueil du projet.

**Puisque vous avez introduit un bug, le pipeline de build est maintenant en √©chec :**

![Pipeline en √©chec](https://user.oc-static.com/upload/2019/05/27/15589774662327_build-failed.png)


En cliquant sur la croix rouge dans la colonne Stage, nous avons le d√©tail de l'erreur (ici, le bug que nous avons introduit) :

![D√©tail de l'erreur d'ex√©cution du pipeline](https://user.oc-static.com/upload/2019/05/27/155897750423_build-failed-detail.png)

#### G√©rez le fix du bug sur GitLab

Pour enregistrer le bug, nous pouvons cr√©er un nouveau Bug directement en cliquant sur le bouton New Issue. Il faut alors remplir les champs ad√©quats comme l'assignee, le milestone, les labels (Bug et User Story) ou la due date :

![Cr√©ation d'une nouvelle issue Bug dans GitLab](https://user.oc-static.com/upload/2019/05/27/15589775778674_new-bug.png)

Une fois l'issue compl√©t√©e, nous avons tous les d√©tails du bug √† corriger et le job en √©chec est automatiquement r√©cup√©r√© :

![Nouveau bug cr√©√©](https://user.oc-static.com/upload/2019/05/27/15589777460194_new-bug-created.png)

Si nous revenons sur le board Development, nous nous apercevons que l'issue cr√©√©e appara√Æt dans la colonne Open. Nous pouvons alors la d√©placer dans la colonne Doing, car nous allons la corriger.

Pour corriger ce bug automatiquement, nous allons cr√©er une merge request, c'est-√†-dire demander √† commiter les changements sur notre branche dans la branche principale `master`. Pour ce faire, il faut aller dans le menu Merge Requests et cliquer sur New Merge Request.

Dans la nouvelle page, il faut choisir la branche que nous voulons merger dans la branche principale (ici, la branche `monbug`) et cliquer sur "Compare branches and continue" :

![Comparaison des branches Master et Monbug](https://user.oc-static.com/upload/2019/05/27/15589789051477_compare-branches.png)

Au prochain √©cran, il faut remplir les champs de fa√ßon ad√©quate, et cliquer sur Submit Merge Request. Pour le champ Description, la syntaxe est "Closes" et le num√©ro du bug, ici, le 6 :
- Title : *WIP: Mon premier bug* ;
- Description : *Closes #6* ;
- Assignee : *Assign to me* ;
- Milestone : *Sprint 1*.

![Description de mon bug](https://user.oc-static.com/upload/2019/05/27/15589790588121_submit-merge-request.png)

Une fois la merge request cr√©√©e, nous avons tous les d√©tails de celle-ci :

![Description de mon bug](https://user.oc-static.com/upload/2019/05/27/15589790991082_merge-request-detail.png)

#### Corrigez votre bug

l est temps de corriger notre bug. Nous allons √©diter le fichier que nous avons modifi√©. Pour cela, nous allons r√©introduire le " **;** " manquant, puis commiter le code corrig√© sur la branche `monbug`.

```
git add spring-petclinic-customers-service/src/main/java/org/springframework/samples/petclinic/customers/CustomersServiceApplication.java
git commit -m "Correction du bug clients"
git push origin monbug
```

Vous allez constater qu'une fois le code push√© sur la branche `monbug`, le pipeline de build se lance afin de v√©rifier que le code que nous avons envoy√© fonctionne.

Une fois que le pipeline s'est termin√© en succ√®s, nous pouvons alors enlever le statut Work in progress en cliquant sur le bouton Resolve WIP status, pour ensuite cliquer sur le bouton Merge :

![Bug r√©solu, mergez les branches !](https://user.oc-static.com/upload/2019/05/27/15589794618626_merge-branches.png)

Le pipeline se lance alors une derni√®re fois pour v√©rifier que le code merg√© ne casse pas la compilation.

Enfin, si nous revenons sur le board Development, nous voyons que le bug est automatiquement ferm√©, suite √† notre merge request.

![Les 2 premi√®res √©tapes du pipeline sont fonctionnelles ‚úÖ](https://user.oc-static.com/upload/2019/05/29/15591253758662_1c3_illus_WHITEBG%20%280-00-17-23%29_2.png)

> Nous avons donc rempli les 3 premi√®res √©tapes de l'int√©gration continue :
> 1. ‚úÖPlanifiez votre d√©veloppement.
> 2. ‚úÖCompilez et int√©grez votre code.
> 3. ‚úÖTestez votre code.
> 4.  Mesurez la qualit√© de votre code.
> 5. G√©rez les livrables de votre application.

## Garantissez la qualit√© de votre code

### Mesurez la qualit√© de votre code

Commen√ßons par **l'analyse de code statique**, afin de contr√¥ler la **qualit√© du code**.

Nous allons donc modifier le pipeline de code, afin d'ajouter cette analyse de code. Il faut alors modifier le fichier `.gitlab-ci.yml` afin qu'il ressemble √† ceci :
```yml
stages:
  - build
  - test
  - quality

cache:
  paths:
    - .m2/repository
  key: "$CI_JOB_NAME"

build_job:
  stage: build
  script:
    - ./mvnw compile
      -Dhttps.protocols=TLSv1.2
      -Dmaven.repo.local=$CI_PROJECT_DIR/.m2/repository
      -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=WARN
      -Dorg.slf4j.simpleLogger.showDateTime=true
      -Djava.awt.headless=true
      --batch-mode --errors --fail-at-end --show-version -DinstallAtEnd=true -DdeployAtEnd=true
  image: openjdk:8-alpine

test_job:
  stage: test
  script:
    - ./mvnw test
      -Dhttps.protocols=TLSv1.2
      -Dmaven.repo.local=$CI_PROJECT_DIR/.m2/repository
      -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=WARN
      -Dorg.slf4j.simpleLogger.showDateTime=true
      -Djava.awt.headless=true
      --batch-mode --errors --fail-at-end --show-version -DinstallAtEnd=true -DdeployAtEnd=true
  image: openjdk:8-alpine

code_quality_job:
  stage: quality
  image: docker:stable
  allow_failure: true
  services:
    - docker:stable-dind
  script:
    - mkdir codequality-results
    - docker run
        --env CODECLIMATE_CODE="$PWD"
        --volume "$PWD":/code
        --volume /var/run/docker.sock:/var/run/docker.sock
        --volume /tmp/cc:/tmp/cc
        codeclimate/codeclimate analyze -f html > ./codequality-results/index.html
  artifacts:
    paths:
      - codequality-results/
```

> Ici, j'ai ajout√© une √©tape suppl√©mentaire de qualit√© de code. L'√©tape (*le stage*) `quality` est d√©fini dans le bloc `stages`. Cela veut dire que le pipeline va ajouter un job de qualit√© √† la suite de la compilation et des tests. Ce job, je l'ajoute √† la fin du fichier et il est appel√© `code_quality_job`.

Dans ce job, nous retrouvons les 3 lignes des √©tapes pr√©c√©dentes, plus d'autres lignes :
- `allow_failure` : cette ligne **autorise l'√©chec de l'√©tape de qualit√©**. Comme ce n'est pas une √©tape critique, nous nous permettons d'autoriser l'√©chec et de laisser le pipeline continuer ;
- `services` : ce nouveau mot cl√© de GitLab permet de **d√©marrer un d√©mon Docker**, pour que l‚Äôex√©cution de notre programme d‚Äôanalyse de code puisse se faire. Cette ligne nous permet d'ex√©cuter Docker au sein de l'image, afin d'ex√©cuter l'analyse de code ;
- `script` : cette ligne est un peu plus compliqu√©e que les lignes de script pr√©c√©dentes. La premi√®re ligne va cr√©er un dossier  `codequality-results/` qui contiendra le r√©sultat de l'analyse de code. La deuxi√®me ligne monte le code √† l'int√©rieur d'une image Docker via le dossier `/code`, et lance l'analyse via le programme `codequality`. Le r√©sultat sera export√© dans le dossier `codequality-results` ;
- `artifact` : cette ligne est un pr√©requis de GitLab si nous voulons voir notre √©volution de qualit√©. Le dossier `codequality-results/` sera stock√© **au sein de GitLab** afin de pouvoir voir le r√©sultat de l'analyse du scan. Ce r√©sultat sera disponible et visible au sein du job `code_quality_job`.

Tout le script est ex√©cut√© au sein de l'image `docker:stable`. Cette image permet de d√©marrer le programme d‚Äôanalyse de code.

Une fois le fichier commit√© sous Git et envoy√© sur GitLab via les commandes suivantes, le pipeline d'int√©gration continue va alors se mettre √† jour et lancer une compilation, suivie d'une analyse statique du code.

Le code est alors **analys√© par GitLab**, et le rapport g√©n√©r√© stock√© au niveau des artefacts. Pour voir le r√©sultat de l'analyse de code, il suffit de naviguer dans le job `code_quality_job`, puis de cliquer sur Browse. Vous aurez alors acc√®s au dossier contenant le r√©sultat de l'analyse de code, et pourrez naviguer au sein de ce fichier, afin de voir les am√©liorations √† apporter au code.

√áa y est, l'√©tape de qualit√© est impl√©ment√©e !

![L'√©tape de qualit√© est impl√©ment√©e ‚úÖ](https://user.oc-static.com/upload/2019/05/29/15591255853183_1c3_illus_WHITEBG%20%280-00-17-23%29_3.png)

> D'autres outils existent pour voir la qualit√© d'un code de d√©veloppement. Le plus connu est **SonarQube**, qui permet d'afficher des rapports de qualit√©, l'√©volution de ceux-ci, ainsi qu'une d√©tection partielle des erreurs. 

### Packagez votre application pour la d√©ployer

La prochaine √©tape apr√®s la qualit√© du code est le **packaging** de l'application, afin de pouvoir la d√©ployer plus facilement. Pour ce projet, nous allons choisir **Docker** comme programme de packaging.

> Si vous n'√™tes pas √† l'aise avec les conteneurs Docker, ils seront expliqu√©s plus en d√©tail **dans la seconde partie de ce cours**, quand nous verrons la livraison continue.

GitLab vient avec une registry Docker incluse, ce qui nous permet de stocker ces images au sein de GitLab. Pour pouvoir packager nos images Docker, il est n√©cessaire d'ajouter une nouvelle √©tape √† notre pipeline d'int√©gration continue. Nous allons une nouvelle fois modifier le fichier `.gitlab-ci.yml` pour ajouter cette nouvelle √©tape. Le fichier final ressemblera alors √† ceci :

```yml
stages:
  - build
  - test
  - quality
  - package

cache:
  paths:
    - .m2/repository
  key: "$CI_JOB_NAME"

build_job:
  stage: build
  script:
    - ./mvnw compile
      -Dhttps.protocols=TLSv1.2
      -Dmaven.repo.local=$CI_PROJECT_DIR/.m2/repository
      -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=WARN
      -Dorg.slf4j.simpleLogger.showDateTime=true
      -Djava.awt.headless=true
      --batch-mode --errors --fail-at-end --show-version -DinstallAtEnd=true -DdeployAtEnd=true
  image: openjdk:8-alpine

test_job:
  stage: test
  script:
    - ./mvnw test
      -Dhttps.protocols=TLSv1.2
      -Dmaven.repo.local=$CI_PROJECT_DIR/.m2/repository
      -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=WARN
      -Dorg.slf4j.simpleLogger.showDateTime=true
      -Djava.awt.headless=true
      --batch-mode --errors --fail-at-end --show-version -DinstallAtEnd=true -DdeployAtEnd=true
  image: openjdk:8-alpine

code_quality_job:
  stage: quality
  image: docker:stable
  allow_failure: true
  services:
    - docker:stable-dind
  script:
    - mkdir codequality-results
    - docker run
        --env CODECLIMATE_CODE="$PWD"
        --volume "$PWD":/code
        --volume /var/run/docker.sock:/var/run/docker.sock
        --volume /tmp/cc:/tmp/cc
        codeclimate/codeclimate analyze -f html > ./codequality-results/index.html
  artifacts:
    paths:
      - codequality-results/

package_job:
  stage: package
  services:
    - docker:stable-dind
  variables:
    DOCKER_HOST: tcp://docker:2375
  script:
    - apk add --no-cache docker
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY
    - ./mvnw install -PbuildDocker -DskipTests=true -DpushImage
      -Dhttps.protocols=TLSv1.2
      -Dmaven.repo.local=$CI_PROJECT_DIR/.m2/repository
      -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=WARN
      -Dorg.slf4j.simpleLogger.showDateTime=true
      -Djava.awt.headless=true
      --batch-mode --errors --fail-at-end --show-version -DinstallAtEnd=true -DdeployAtEnd=true
  image: openjdk:8-alpine
```

> J'ajoute dans le fichier la derni√®re √©tape de mon pipeline d'int√©gration continue, l'√©tape (le *stage*) `package`, qui s'ex√©cutera √† la suite de l'√©tape `quality`. J'ajoute ensuite le job `package_job` associ√© √† cette √©tape de qualit√©.

Ce job suppl√©mentaire compile le projet et **l'encapsule dans un conteneur**. Il est ensuite pouss√© sur la registry de GitLab. Nous retrouvons toutes les lignes que nous avons vues pr√©c√©demment. La partie `script` lance cependant quelques commandes suppl√©mentaires :
- tout d'abord, nous **installons le client Docker** dans l'image `openjdk:8-alpine` afin de pouvoir lancer les commandes propres √† Docker ;
- ensuite, nous **nous connectons sur la registry interne de GitLab** afin de pouvoir pousser les images Docker de fa√ßon s√©curis√©e ;
- enfin, nous **lan√ßons la commande Maven** de cr√©ation de l'image Docker.

Ce processus nous permettra, dans la livraison continue, de pouvoir **d√©ployer facilement** le m√™me code sur diff√©rents environnements. Il sert aussi √† figer le code compil√© dans un **package immuable**. De ce fait, nous pouvons facilement red√©ployer le m√™me code compil√© sur n'importe quel autre environnement. Cela assure que le code ne soit pas modifi√© entre deux environnements, et qu'un code test√© soit **d√©ploy√© partout de la m√™me fa√ßon**. Les images Docker ainsi packag√©es se retrouvent sur la page de la registry :

![Registry GitLab de votre projet, avec les packages du pipeline](https://user.oc-static.com/upload/2019/05/27/15589802871223_registry.png)

Nous avons maintenant toutes les √©tapes n√©cessaires pour l'int√©gration continue. Comme pr√©vu, notre code est **compil√©** en continu, **test√©**, **analys√©** puis **packag√©**, pr√™t √† √™tre d√©ploy√© sur de nouveaux environnements.

![Toutes les √©tapes de l'int√©gration continue sont impl√©ment√©es ‚úÖ](https://user.oc-static.com/upload/2019/05/29/1559125627351_1c3_illus_WHITEBG%20%280-00-17-23%29_4.png)

### Les autres outils de l'int√©gration continue

Vous avez donc vu tout au long de cette partie comment mettre en place **l'int√©gration continue avec GitLab**, mais sachez qu'il existe d'autres outils reprenant les m√™mes concepts. Le plus connu et le plus utilis√© d'entre eux est [Jenkins](https://jenkins.io/). Avec cet outil, vous pouvez impl√©menter toutes les √©tapes pr√©c√©demment vues. De plus, Jenkins utilise maintenant un fichier de description comme GitLab, qui s'appelle [Jenkinsfile](https://jenkins.io/doc/book/pipeline/jenkinsfile/).

Le principe est strictement le m√™me que **GitLab** : il s'agit d'un **fichier de description du pipeline** d'int√©gration continue qui va contenir toutes les √©tapes √† lancer, afin de garantir que le code compile et soit de qualit√© √† tout moment. Cependant, il est n√©cessaire d'installer Jenkins dans votre entreprise, de le configurer, de le maintenir et de le mettre √† jour, ce qui peut s'av√©rer **long et fastidieux**.

Pour ceux qui ne voudraient pas passer leur temps √† maintenir ce genre d'outils, il existe aussi d'autres outils en mode **Software-as-a-Service** (SaaS), o√π la maintenance et l'√©volution sont garanties par le fournisseur. Ces outils peuvent √™tre mieux adapt√©s pour mettre en place rapidement et sans effort un pipeline d'int√©gration continue. Les outils les plus connus dans cet √©cosyst√®me sont [Travis CI](https://travis-ci.org/) et [CircleCI](https://circleci.com/).

Le gros avantage de ces outils est que la **maintenance** n'est pas √† la charge de l'√©quipe, mais du **fournisseur**. De plus, ces outils peuvent se connecter automatiquement sur Github.com pour la plupart, ce qui √©vite aussi les configurations longues et fastidieuses des diff√©rents outils.

Enfin, GitHub a sorti une beta de son nouveau service √† destination des d√©veloppeurs, afin de pouvoir impl√©menter rapidement des pipelines d'int√©gration continue : **GitHub Actions**. Le principe est toujours le m√™me : un fichier `.workflow` permet de cr√©er un pipeline, afin de compiler et d√©ployer du code sur n'importe quelle plateforme. L'avantage principal de GitHub Actions est que ce dernier est directement int√©gr√© dans GitHub.

> Nous avons donc rempli les deux derni√®res √©tapes de l'int√©gration continue :
> 1. ‚úÖPlanifiez votre d√©veloppement.
> 2. ‚úÖCompilez et int√©grez votre code.
> 3. ‚úÖTestez votre code.
> 4. ‚úÖMesurez la qualit√© de votre code.
> 5. ‚úÖG√©rez les livrables de votre application.

Et voil√† ! Vous avez mis en place toutes les √©tapes de l'int√©gration continue ! üëèüéâ

**Dans la prochaine partie**, nous mettrons en place la livraison continue, du d√©ploiement √† la supervision, en passant par les tests en production.

## Exercice ! Mettez en place le pipeline CI de votre application avec GitLab

Vous √™tes le nouvel **ing√©nieur DevOps** de l'entreprise **PetClinic**. L‚Äô√©quipe de d√©veloppement se repose sur un serveur afin de compiler l‚Äôapplication avant la livraison. Cependant, aucun test unitaire n‚Äôest ex√©cut√©, et les clients se plaignent de la mauvaise qualit√© de l‚Äôapplication.

Votre premi√®re mission est de mettre en place un pipeline d‚Äôint√©gration continue automatis√© afin de compiler l‚Äôapplication, de lancer les tests unitaires associ√©s, et de stocker les livrables sur un serveur afin de pr√©parer le d√©ploiement.

### Description

#### Objectif

L‚Äôobjectif de cette activit√© est **d‚Äô√©crire le pipeline d‚Äôint√©gration continue** n√©cessaire √† l‚Äôint√©gration du projet. Pour cette activit√©, nous utiliserons le projet exemple Java **PetClinic** comme vu dans ce cours, mais dans sa version non microservice.

#### Donn√©es

Les donn√©es sont le [repository GitHub du projet Petclinic](https://github.com/spring-projects/spring-petclinic). Ce repository contient tous les √©l√©ments n√©cessaires au fonctionnement de l‚Äôapplication. Ces √©l√©ments sont :
- le code source ;
- les tests unitaires ;
- la documentation.

#### Instructions

Clonez le repository dans votre repository GitLab, et mettez en place un pipeline d‚Äôint√©gration continue contenant chacune des √©tapes n√©cessaires √† sa bonne ex√©cution.

Comme vu dans ce cours, ces √©tapes sont les 4 √©tapes de l‚Äôint√©gration continue : **compilation**, **test**, **qualit√©** et gestion des **livrables** (package + deploy).

Afin de pouvoir livrer l‚Äôapplication et la stocker sous GitLab, vous aurez besoin de modifier le fichier pom.xml et d'ajouter un fichier ci-settings.xml √† la racine de votre projet. Pour vous aider, voici les fichiers :
- le [pom.xml](https://s3-eu-west-1.amazonaws.com/course.oc-static.com/courses/2035736/activit%C3%A9/pom.xml), vous pouvez directement remplacer votre pom.xml par celui-ci ;
- le [ci-settings.xml](https://s3-eu-west-1.amazonaws.com/course.oc-static.com/courses/2035736/activit%C3%A9/ci-settings.xml) √† ajouter √† la racine de votre projet.

Ces fichiers doivent contenir le n√©cessaire afin de pouvoir s‚Äôauthentifier aupr√®s du repository de GitLab, ainsi qu‚Äôavoir les droits n√©cessaires pour envoyer le livrable g√©n√©r√©. Pour ceci, vous pouvez vous inspirer de [la page officielle de GitLab](https://docs.gitlab.com/ee/user/project/packages/maven_repository.html).

Une image Docker a √©t√© pr√©par√©e pour vous afin de faciliter toutes les √©tapes de l'int√©gration continue, et contenant tous les outils n√©cessaires au bon d√©roulement des √©tapes.

Une fois toutes les √©tapes valid√©es, **une phrase sera affich√©e** dans les logs de l'√©tape de d√©ploiement. C'est en voyant cette phrase que vous saurez que vous avez r√©ussi cette mission !

Le nom de l'image √† utiliser dans le `.gitlab-ci.yml` est l'image `laurentgrangeau/oc-devops:latest`

### Question

Quelle est la phrase affich√©e lors de l'√©tape de d√©ploiement ?

### R√©ponse

<details>
    <summary>Voir la r√©ponse</summary>
    Something small enough to escape casual notice.
</details>

---

## Qu'est-ce que la livraison continue ?

**La livraison continue** est la suite logique de l'int√©gration continue. Dans l'int√©gration continue, nous cherchons √† ce que le code **compile** bien, mais aussi qu'il soit **fonctionnel** en production et de **qualit√©**, en lan√ßant le plus r√©guli√®rement possible les **tests unitaires**. Mais il existe d'autres **types** de tests, tout aussi importants, pour garantir la qualit√© du code. Ces tests ne peuvent cependant pas √™tre lanc√©s sans avoir un environnement d√©ploy√©.

> Attention, la **livraison continue** ne doit pas √™tre confondue avec le **d√©ploiement continu**, qui est la suite logique de la livraison continue. Ces deux disciplines ont comme objectif de d√©ployer une application en production. La diff√©rence se trouve dans l'automatisation du d√©ploiement en production. La livraison continue s'arr√™te avant la production, et la mise en production reste un acte manuel (que ce soit avec un outil, ou automatis√© via un clic de bouton, ou bien manuellement). La mise en production est soumise alors √† la **validation d'un √™tre humain**. <br/><br/>
> Le **d√©ploiement continu**, quant √† lui, est l'extension de la livraison continue : le d√©ploiement se fait de mani√®re **automatis√©e** par un pipeline. Toutes les √©tapes de compilation, tests unitaires et autres tests automatis√©s doivent √™tre alors au vert avant de proc√©der au d√©ploiement.

La **livraison continue** est une discipline o√π l'application est construite de mani√®re √† pouvoir √™tre mise en production √† n'importe quel moment.

Pour atteindre la mise en oeuvre de la livraison continue sur une application, il est n√©cessaire de mettre en place plusieurs √©tapes suppl√©mentaires au sein de notre pipeline.

> Pour mettre en place la **livraison continue**, vous devez mettre en place **5 √©tapes** :
> 1. La codification de l'infrastructure avec l'**Infrastructure-as-Code**.
> 2. Le **d√©ploiement** de votre application.
> 3. Le **test** de votre application en environnement de test.
> 4. La **supervision** de l'application.
> 5. La mise en place de **notifications** d'alerte.

### √âtape 1 : Codifiez votre infrastructure avec l'Infrastructure-as-Code

> L'**Infrastructure-as-Code** est une pratique qui consiste √† **d√©crire une infrastructure avec du code**. Ce code est alors stock√© avec le code de l'application, et fait partie int√©grante de cette derni√®re.

Les avantages sont nombreux :

- possibilit√© de cr√©er des environnements **√† la demande** ;
- **cr√©ation d'environnement en quelques minutes**, contre plusieurs semaines dans une entreprise classique ;
- **pilotage de l'infrastructure** gr√¢ce au pipeline de livraison continue ;
- **connaissance des logiciels** install√©s sur la plateforme, gr√¢ce √† l'outillage ;
- **mont√©e de version** des environnements automatis√©s.

> Les outils principaux de l'Infrastructure-as-Code sont **Docker**, **Chef**, **Puppet**, **Ansible** et **Terraform**.

### √âtape 2 : D√©ployez votre application

L'√©tape la plus importante de la livraison continue est le **d√©ploiement du package** que nous avons pr√©c√©demment cr√©√© lors de l'int√©gration continue. Les avantages d'utiliser un outil pour **automatiser le d√©ploiement** de l'application sont nombreux :
- cela permet √† l'√©quipe de **se concentrer sur le d√©veloppement**, l√† o√π elle a sa valeur √† ajouter ;
- n'importe qui dans l'√©quipe peut d√©ployer des logiciels ;
- les d√©ploiements deviennent beaucoup moins sujets aux **erreurs** et beaucoup plus **reproductibles** ;
- d√©ployer sur un **nouvel environnement** est facile ;
- les d√©ploiements peuvent √™tre **tr√®s fr√©quents**.

> Pour pouvoir d√©ployer les artefacts pr√©c√©demment cr√©√©s, vous pourrez utiliser **Spinnaker**, **XLDeploy** ou **UrbanCode**.

### √âtape 3 : Testez votre application

C'est dans cette √©tape que nous allons ajouter **d'autres types de tests**, plus pertinents et plus fonctionnels, afin de garantir que l'application **fonctionne comme nous l'avons estim√©**.

L'avantage de tester √† ce stade du pipeline est que l'application tourne sur un environnement de test, **presque identique √† celui de la production**. Son comportement sera donc le plus fid√®le possible √† celui qu'elle aura en production.

Ces tests peuvent √™tre de diff√©rents types :

#### Test d'acceptance

Les **tests d'acceptance** sont des tests formels ex√©cut√©s pour v√©rifier si un syst√®me satisfait √† ses exigences op√©rationnelles. Ils exigent que l'application enti√®re soit op√©rationnelle et se concentrent sur la r√©plication des comportements des utilisateurs. Mais ils peuvent aussi aller plus loin en mesurant la performance du syst√®me, et rejeter les changements si certains objectifs ne sont pas atteints.

Ces tests peuvent √™tre **automatis√©s**, mais aussi **manuels**, avec une √©quipe de test d√©di√©e qui regardera si le logiciel correspond au besoin.

> Pour lancer des tests d'acceptance, vous pourrez utiliser **Confluence**, **FitNesse** ou **Ranorex**.

#### Test de performance

Les **tests de performance** v√©rifient le comportement du syst√®me lorsqu'il est soumis √† une charge importante. Ces tests ne sont pas fonctionnels et peuvent prendre diff√©rentes formes pour comprendre la fiabilit√©, la stabilit√© et la disponibilit√© de la plateforme. Par exemple, il peut s'agir d'observer les temps de r√©ponse lors de l'ex√©cution d'un grand nombre de requ√™tes, ou de voir comment le syst√®me se comporte avec une quantit√© importante de donn√©es.

Les tests de performance sont par nature assez co√ªteux √† mettre en ≈ìuvre et √† ex√©cuter, mais ils peuvent vous aider √† comprendre si de nouveaux changements vont d√©grader votre syst√®me.

> Pour faire des tests de performance, vous pourrez utiliser **JMeter**, **Apache Bench** ou **Gatling**.

#### Smoke test

Les **smoke tests** sont des tests de base qui v√©rifient les fonctionnalit√©s de base de l'application. Ils sont con√ßus pour √™tre rapides √† ex√©cuter, et leur but est de vous donner l'assurance que les **principales caract√©ristiques de votre syst√®me fonctionnent comme pr√©vu**. Ils peuvent √™tre utiles juste apr√®s une nouvelle build, pour d√©cider si vous pouvez ou non ex√©cuter des tests plus co√ªteux, ou juste apr√®s un d√©ploiement pour s'assurer que l'application fonctionne correctement dans le nouvel environnement d√©ploy√©.

Par exemple, les smoke tests peuvent s'assurer que la base de donn√©es r√©pond et est correctement configur√©e, mais aussi que les diff√©rents composants sont pr√©sents et envoient des donn√©es correctes, comme des API qui devraient r√©pondre un code HTTP 200, ou une page web qui devrait s'afficher.

> Pour s'assurer du bon fonctionnement de l'application, vous pourrez utiliser **Selenium**, **SoapUI** ou **Cypress**.

### √âtape 4 : Supervisez le comportement de votre application

Le **monitoring**, ou ***supervision***, intervient une fois que notre application est d√©ploy√©e sur un environnement, que ce soit un environnement de **staging**, de **test**, de **d√©monstration** ou bien l'environnement de **production** lui-m√™me.

Le principe est de **r√©cup√©rer certaines m√©triques** qui ont du sens pour ceux qui interviennent sur l'application. Cela peut √™tre par exemple le nombre de connexions HTTP, le nombre de requ√™tes √† la base de donn√©es, le temps de r√©ponse de certaines pages ; mais aussi des m√©triques plus orient√©es m√©tier, comme le chiffre d'affaires g√©n√©r√©, ou le nombre de personnes inscrites sur l'application.

> Pour avoir un monitoring de vos applications, vous pourrez utiliser la suite **Elastic**, **Prometheus** ou **Graylog**.

Les m√©triques peuvent √™tre aussi sur la partie livraison en elle-m√™me, ou sur le processus de d√©veloppement. Par exemple, l'√©quipe peut mesurer le nombre de d√©ploiements qu'elle effectue par jour, ou encore deux autres indicateurs qui sont importants afin de voir la performance de l'√©quipe sur la correction d'erreurs qui peuvent survenir en production :

#### Le Mean-Time-Between-Failure

Le **Mean-Time-Between-Failure** (ou MTBF) est le temps moyen qui s√©pare deux erreurs en production. Plus ce temps est √©lev√©, plus le syst√®me est stable et fiable, notamment du fait de la qualit√© des tests qui sont jou√©s lors de la livraison continue.

#### Le Mean-Time-To-Recover

Le **Mean-Time-To-Recover** (ou MTTR) est le temps moyen de correction entre deux erreurs de production. Plus ce temps est faible, plus l'√©quipe est apte √† d√©tecter des erreurs et √† les corriger rapidement.

> Des outils comme **Dynatrace**, **Sysdig** ou **New Relic** permettent d'avoir ces m√©triques.

### √âtape 5 : Mettez en place des notifications d'alertes

La premi√®re version d'une nouvelle fonctionnalit√© ou d'un nouveau produit ne couvre souvent pas enti√®rement les besoins des clients. M√™me lorsque l'√©quipe passe des semaines ou des mois √† construire quelque chose, le produit final est souvent vou√© √† manquer des fonctionnalit√©s importantes. C'est le principe du **Minimum Viable Product** (MVP) en Agile.

Il arrive donc tr√®s souvent de livrer des logiciels **incomplets ou bugg√©s**, si l'√©quipe veut aller assez vite. Au lieu de vouloir √©viter cela, il est n√©cessaire d'adopter l'id√©e de **livrer des petites pi√®ces de valeur**.

En livrant **plus vite**, nous pouvons r√©parer les bugs **tant que les livraisons restent petites**, et que nous savons ce qui a √©t√© modifi√© dans l'application. Quand les d√©veloppements grossissent, ils deviennent plus difficiles √† g√©rer et √† remanier. Un feedback rapide, gr√¢ce aux **tests en production** et au **monitoring**, permet d'intervenir et de corriger le probl√®me d√®s que possible. Il nous permet d'apprendre des clients, et des erreurs, au bon moment.

Une fois le d√©ploiement fini et les diff√©rents tests effectu√©s, il est n√©cessaire d'avoir un feedback rapide de l'utilisation du logiciel. En effet, si le d√©ploiement de la nouvelle version du logiciel apporte des bugs malgr√© les diff√©rents tests effectu√©s, il faut alors les d√©tecter le plus rapidement possible, afin de pouvoir proposer une nouvelle correction au logiciel.

> Pour avoir un feedback rapide de vos d√©ploiements, vous pourrez tout simplement utiliser **Slack**, **Trello** ou **Twitter**. 

## Codifiez votre infrastructure

### Construisez les images de votre application avec Docker

Notre application PetClinic est construite √† partir de fichiers, nomm√©s `dockerfiles`, d√©j√† pr√©sents dans le contr√¥le de code source. Ces `dockerfiles` sont pr√©sents dans le r√©pertoire `Docker` du projet et contiennent les lignes suivantes :
```Dockerfile
FROM openjdk:8-jre-alpine

VOLUME /tmp

ARG DOCKERIZE_VERSION
ARG ARTIFACT_NAME
ARG EXPOSED_PORT

ENV SPRING_PROFILES_ACTIVE docker

ADD https://github.com/jwilder/dockerize/releases/download/${DOCKERIZE_VERSION}/dockerize-alpine-linux-amd64-${DOCKERIZE_VERSION}.tar.gz dockerize.tar.gz
RUN tar xzf dockerize.tar.gz
RUN chmod +x dockerize

ADD ${ARTIFACT_NAME}.jar /app.jar

RUN touch /app.jar

EXPOSE ${EXPOSED_PORT}

ENTRYPOINT ["java", "-XX:+UnlockExperimentalVMOptions", "-XX:+UseCGroupMemoryLimitForHeap", "-Djava.security.egd=file:/dev/./urandom","-jar","/app.jar"]
```

Ce `dockerfile` part d'une image qui contient d√©j√† **la version 8 de Java** et copie tous les .jar des diff√©rents projets, afin de construire les diff√©rentes images associ√©es. Enfin, la derni√®re √©tape de ce `dockerfile` est de lancer la commande `Java` avec le jar associ√©.

Dans cette partie du cours, vous allez modifier le `dockerfile` pour voir l'impact de l'Infrastructure-as-Code sur votre pipeline de d√©ploiement. Pour ce faire, ouvrez le fichier `Dockerfile` pr√©sent dans le dossier Docker, afin de modifier la version du runtime de Java en version `openjdk:13-alpine` :

![Changez la version de l'openjdk dans le dockerfile](https://user.oc-static.com/upload/2019/05/23/15586191895254_change-openjdk.png)

Avant de pousser ce fichier sur Git, vous allez modifier la version de release de chaque `pom.xml` pr√©sent dans le projet, pour incr√©menter le num√©ro de version des images Docker cr√©√©es, et ainsi ne pas √©craser les versions pr√©c√©demment build√©es :

![Changez la version des images Docker cr√©√©es dans les fichiers pom.xml](https://user.oc-static.com/upload/2019/05/23/15586192536832_modify-pom.png)

**Il y a plusieurs `pom.xml` o√π il faut ajouter le bon num√©ro de version !**

Une fois ces modifications faites, poussez les fichiers sur Git :
```bash
git add .
git commit -m "Modification de la version de Java et incr√©mentation du num√©ro de version"
git push origin master
```

Le pipeline d'int√©gration continue devrait se lancer :

![Le pipeline se lance √† nouveau](https://user.oc-static.com/upload/2019/05/23/15586193101822_pipeline-launch.png)

Et la registry Docker devrait contenir les nouvelles images build√©es gr√¢ce au pipeline.

Vous venez de voir √† quel point l'**Infrastructure-as-Code** est pratique pour tester rapidement le changement de version d'un framework, ou le changement de version d'un middleware comme Apache ou IIS. En ne changeant que quelques lignes, nous pouvons alors relancer tout le pipeline, afin de voir s'il y a un impact sur le code applicatif.

### D√©ployez votre application avec Docker Compose

L'Infrastructure-as-Code ne s'arr√™te pas l√†. Dans le cas de Docker, toute l'application peut √™tre d√©ploy√©e gr√¢ce au fichier `docker-compose.yml` qui contient toute la d√©finition de l'application, la relation entre les images Docker et le sens de d√©marrage de celles-ci.

Le fichier `docker-compose.yml` pr√©sent dans le repository Git d√©finit des images en dur. Vous allez **remplacer le nom des images par les nouvelles images que vous venez de cr√©er**.

Remplacez alors toutes les lignes contenant `mszarlinski/` par votre nom de registry (chez moi, `registry.gitlab.com/laurentgrangeau/`). De plus, ajoutez aussi en bout de ligne le num√©ro de version de l'image que vous venez de cr√©er `:2.0.7`

Le fichier `docker-compose.yml` devrait ressembler √† ceci (le fichier est volontairement tronqu√©) :

```yml
version: '2'

volumes:
  graf-data:

services:
  config-server:
    image: registry.gitlab.com/laurentgrangeau/spring-petclinic-microservices/spring-petclinic-config-server:2.0.7
    container_name: config-server
    mem_limit: 512M
    ports:
     - 8888:8888

  discovery-server:
    image: registry.gitlab.com/laurentgrangeau/spring-petclinic-microservices/spring-petclinic-discovery-server:2.0.7
    container_name: discovery-server
    mem_limit: 512M
    depends_on:
      - config-server
    entrypoint: ["./dockerize","-wait=tcp://config-server:8888","-timeout=120s","--","java", "-XX:+UnlockExperimentalVMOptions", "-XX:+UseCGroupMemoryLimitForHeap", "-Djava.security.egd=file:/dev/./urandom","-jar","/app.jar"]
    ports:
     - 8761:8761

...
```

Et voil√†, vos fichiers Docker et Docker Compose sont pr√™ts √† √™tre lanc√©s par votre pipeline de livraison continue.

> Nous avons donc rempli la premi√®re √©tape de la livraison continue : 
> 1. ‚úÖLa codification de l'infrastructure avec l'**Infrastructure-as-Code**.
> 2. Le **d√©ploiement** de votre application.
> 3. Le **test** de votre application en environnement de test.
> 4. La **supervision** de l'application.
> 5. La mise en place de **notifications** d'alerte.

## D√©ployez et testez votre code sur diff√©rents environnements

### Pr√©parez votre environnement de travail

Afin de vous faciliter la t√¢che et de ne pas installer des d√©pendances inutiles, je vous conseille de cr√©er un environnement sur le site [Play-With-Docker](https://labs.play-with-docker.com/). Ce site va vous permettre de cr√©er une infrastructure Docker rapidement. Rendez-vous sur le site, et connectez-vous avec vos identifiants Docker Hub.

Une fois connect√©, une session de 4 heures est cr√©√©e afin de vous permettre de d√©ployer vos images. Sur la page d'accueil, cliquez sur l'ic√¥ne üîß et s√©lectionnez le template **3 Managers and 2 Workers**.

Cela va vous cr√©er un cluster Docker Swarm, n√©cessaire au d√©ploiement des images. Une fois le cluster cr√©√©, vous allez r√©cup√©rer l'URL de l'environnement. Il suffit de copier l'URL pr√©sente dans la case SSH.

![Copiez l'URL SSH de votre Docker Swarm sur le Play-With-Docker](https://user.oc-static.com/upload/2019/05/23/15586194362038_pwd-ssh.png)

Cette URL sera utilis√©e pour configurer l'environnement de d√©ploiement dans le fichier `.gitlab-ci.yml`. Maintenant, modifiez ce fichier pour ajouter deux nouvelles lignes. La premi√®re ligne √† ajouter est au niveau de `variables`. Cette nouvelle variable va contenir l'URL copi√©e pr√©c√©demment (`ip172-18-0-51-bihm1906chi000b37l6g` chez moi) :

```yml
PWD: ip172-18-0-51-bihm1906chi000b37l6g
```

La deuxi√®me ligne est √† ajouter juste apr√®s l'√©tape `package`. Cette √©tape suppl√©mentaire sera le d√©ploiement des images sur un environnement de staging :

```yml
deploy_staging_job:
  stage: deploy
  image: docker:stable
  script:
    - apk add --no-cache openssh-client py-pip python-dev libffi-dev openssl-dev gcc libc-dev make
    - pip install docker-compose
    - export DOCKER_HOST=tcp://$PLAYWD.direct.labs.play-with-docker.com:2375
    - docker-compose down
    - docker-compose up -d
  environment:
    name: staging
    url: http://$PLAYWD-8080.direct.labs.play-with-docker.com
```

La syntaxe est la m√™me que les pr√©c√©dentes √©tapes. Dans la partie script, nous avons ajout√© la copie du fichier `docker-compose.yml`, ainsi que le dossier `docker`. Enfin, nous d√©marrons le projet gr√¢ce √† Docker Compose.

Si tout s'est bien pass√©, vous devriez voir appara√Ætre dans vos environnements (*Op√©rations > Environnements*), le nouvel environnement **Staging**.

![Votre nouvel environnement de staging](https://user.oc-static.com/upload/2019/05/23/15586195611102_env-staging.png)

Vous pouvez alors cliquer sur le lien "*Open live environment*" sur la droite de cet environnement, afin de voir l'application d√©ploy√©e.

![Votre application d√©ploy√©e](https://user.oc-static.com/upload/2019/05/23/15586196079905_petclinic.png)

Maintenant que l'environnement **Staging** est d√©ploy√©, il est possible de lancer des tests impossibles √† lancer lors de la phase d'int√©gration continue. Dans ce cours, nous allons lancer un test de performance, afin de mesurer les temps de r√©ponse de l'application. Pour ce faire, vous allez utiliser Apache Benchmark pour simuler de la charge sur le serveur.

Il faut alors ajouter de nouvelles lignes dans le fichier `.gitlab-ci.yml`, afin de lancer les tests de performance sur le nouvel environnement :

```yml
performance_job:
  stage: performance
  image: docker:git
  variables:
    URL: http://$PLAYWD-8080.direct.labs.play-with-docker.com/
  services:
    - docker:stable-dind
  script:
    - apk add --no-cache curl
    - x=1; while [[ "$(curl -s -o /dev/null -w ''%{http_code}'' http://$PLAYWD-8080.direct.labs.play-with-docker.com/)" != "200" || $x -le 60 ]]; do sleep 5; echo $(( x++ )); done || false
    - mkdir gitlab-exporter
    - wget -O ./gitlab-exporter/index.js https://gitlab.com/gitlab-org/gl-performance/raw/master/index.js
    - mkdir sitespeed-results
    - docker run --shm-size=1g --rm -v "$(pwd)":/sitespeed.io sitespeedio/sitespeed.io:6.3.1 --plugins.add ./gitlab-exporter --outputFolder sitespeed-results $URL
    - mv sitespeed-results/data/performance.json performance.json
  artifacts:
    paths:
      - sitespeed-results/
    reports:
      performance: performance.json
```

Dans ce nouveau bloc, la syntaxe reste la m√™me. Nous r√©cup√©rons dans un premier temps l'utilitaire de test de performance dans le bloc `script`. Nous lan√ßons ensuite une application qui va se charger de tester notre site et d'en extraire des m√©triques de performance. Ces m√©triques sont ensuite upload√©es sur GitLab afin d'√™tre accessibles.

Ensuite, modifiez aussi le d√©but du fichier afin d'ajouter une nouvelle ligne dans le bloc `stages` :

```yml
stages:
  - build
  - test
  - quality
  - package
  - deploy
  - performance
```

Enfin, une fois l'environnement de staging d√©ploy√© et test√©, il ne reste plus qu'√† d√©ployer l'application sur l'environnement de production. Pour cela, vous allez une nouvelle fois modifier le fichier `.gitlab-ci.yml` afin d'ajouter l'√©tape de mise en production :

```yml
deploy_prod_job:
  stage: deploy
  image: docker:stable
  script:
    - apk add --no-cache openssh-client py-pip python-dev libffi-dev openssl-dev gcc libc-dev make
    - pip install docker-compose
    - export DOCKER_HOST=tcp://$PLAYWD.direct.labs.play-with-docker.com:2375
    - docker-compose down
    - docker-compose up -d
  environment:
    name: prod
    url: http://$PLAYWD-8080.direct.labs.play-with-docker.com
  when: manual
```

Dans cette √©tape, nous ajoutons le mot cl√© `when: manual` afin de ne d√©ployer en production qu'avec l'intervention d'un √™tre humain. La validation est requise afin de savoir s'il existe des erreurs lors du d√©ploiement sur **staging**. Si des erreurs existent, il n'y aura alors pas de mise en production.

Sur votre pipeline de livraison continue, le d√©ploiement manuel est symbolis√© par l'ic√¥ne ‚ñ∂Ô∏è √† c√¥t√© de l'√©tape `deploy_prod` :

![Le d√©ploiement manuel sur GitLab CI](https://user.oc-static.com/upload/2019/05/23/15586196445312_manual-deploy.png)

Ces erreurs seront analys√©es lors de la prochaine √©tape : le **monitoring**.

Enfin, une technique largement utilis√©e lors de l'utilisation de la livraison continue est le **Canary Release**. Le principe du **Canary Release** est le m√™me que dans les mines de charbon. √Ä l'√©poque, les mineurs de charbon qui descendait √† la mine pla√ßaient un canari devant eux, au bout d'une perche dans une cage. Si le canari mourait, cela voulait dire que l'air √©tait non respirable et les mineurs avaient le temps de rebrousser chemin afin d'√©viter un sort fatal.

Le principe est le m√™me dans le d√©ploiement : une partie seulement des utilisateurs vont √™tre redirig√©s vers la nouvelle version de production, et si quelque chose se passe mal, il n'y aura uniquement qu'une petite partie des utilisateurs qui sera impact√©e. Pour le mettre en place sur notre projet, modifiez le fichier `.gitlab-ci.yml` en ajoutant un nouveau bloc `canary` :

```yml
canary_job:
  stage: canary
  image: docker:stable
  script:
    - apk add --no-cache openssh-client py-pip python-dev libffi-dev openssl-dev gcc libc-dev make
    - pip install docker-compose
    - export DOCKER_HOST=tcp://$PLAYWD.direct.labs.play-with-docker.com:2375
    - docker-compose down
    - docker-compose up -d
  environment:
    name: prod
    url: http://$PLAYWD-8080.direct.labs.play-with-docker.com
  when: manual
  only:
    - master
```

Le principe ici est exactement le m√™me que la production, la diff√©rence √©tant que le d√©ploiement en canary est d√©corr√©l√© de la production.

Ensuite, modifiez le d√©but du fichier afin que dans le bloc `stages` soit ajout√©e l'√©tape `canary` :

```yml
stages:
  - build
  - test
  - quality
  - package
  - canary
  - deploy
  - performance
```

Nous avons maintenant un environnement qui se d√©ploie en parall√®le de la production, et qui contient uniquement une sous-partie des utilisateurs. Cet environnement sera tr√®s utile afin de faire des analyses en temps r√©el du comportement de l'application, et voir s'il n'y a pas d'erreurs.

Nous avons maintenant un pipeline complet de livraison continue, de la compilation du projet au d√©ploiement sur un environnement de **staging**, une possibilit√© de d√©ploiement en production via l'intervention d'une personne de l'√©quipe d'ops, par exemple, et un environnement Canary qui contient un sous-ensemble des utilisateurs, afin de voir comment se comporte l'application.

> Nous avons donc rempli les √©tapes 2 et 3 de la livraison continue :  
> 1. ‚úÖLa codification de l'infrastructure avec l'**Infrastructure-as-Code**.
> 2. ‚úÖLe **d√©ploiement** de votre application.
> 3. ‚úÖLe **test** de votre application en environnement de test.
> 4. La **supervision** de l'application.
> 5. La mise en place de **notifications** d'alerte.

## Monitorez votre application

Afin de savoir si le d√©ploiement d'un syst√®me s'est bien d√©roul√©, il est n√©cessaire de le monitorer, ou le **superviser**. Cela permet de **prendre des d√©cisions** plus rapides, comme le rollback automatique d'une application si celle-ci ne fonctionne pas.

**Les deux derni√®res √©tapes** de notre pipeline de livraison continue sont donc le **monitoring** de l'application, afin de savoir si celle-ci fonctionne correctement, ou pr√©sente des erreurs, ainsi que l'activation de notifications en cas de probl√®me, pour avoir un **feedback rapide**.

### Supervisez votre application avec Prometheus

Dans cette section, vous allez ajouter dans GitLab la r√©cup√©ration des m√©triques de l'application. Lors du d√©ploiement de l'application, des m√©triques sont expos√©es par **Prometheus**, qui est un des composants de notre stack technique.

Le serveur Prometheus est accessible sur le port 9091, auquel vous pouvez acc√©der en cliquant sur le num√©ro de port 9091 qui est apparu sur le site Play-with-Docker :

![Acc√©dez √† Prometheus via le Play-with-Docker](https://user.oc-static.com/upload/2019/05/23/15586223806345_pwd-prometheus.png)

Ce serveur Prothemeus r√©cup√®re √©norm√©ment de m√©triques de l'application, des syst√®mes sous-jacents, ainsi que des images Docker, comme le nombre de connexions par seconde, le nombre de connexions total, etc. Il expose aussi des m√©triques applicatives, comme le nombre d'animaux cr√©√©s ou mis √† jour.

Pour r√©cup√©rer ces m√©triques dans GitLab, il suffit d'aller dans le menu **Settings**, **Integrations**, puis **Prometheus**.

Ensuite, il faut activer l'int√©gration avec Prometheus, et le configurer. Cochez la case **Active**, renseignez l'URL du serveur Prometheus ; dans mon cas : `http://ip172-18-0-8-biiabu86chi000em9j9g-9091.direct.labs.play-with-docker.com/`et sauvegardez :

![Configurez Prometheus](https://user.oc-static.com/upload/2019/05/23/15586225480542_prometheus.png)

Nous allons ensuite d√©finir une m√©trique que nous allons suivre, afin de voir si l'application √† un probl√®me. Cliquez alors sur **New Metric** et ajoutez les informations suivantes :

![Configurez une nouvelle m√©trique sur Prometheus](https://user.oc-static.com/upload/2019/05/23/15586226004055_new-metric.png)

GitLab va alors r√©cup√©rer la m√©trique `http_server_requests_seconds_count` depuis le serveur Prometheus, et l'ajouter dans sa base de donn√©es interne. Suite √† cela, nous pouvons alors voir les graphes de ces m√©triques dans le menu **Operations**, puis **Metrics** o√π nous avons l'√©volution des connexions HTTP au fur et √† mesure du temps :

![Observez vos m√©triques](https://user.oc-static.com/upload/2019/05/23/1558622656011_metrics.png)

Ces m√©triques sont tr√®s utiles pour prendre des d√©cisions sur le d√©ploiement en production. Ici, nous voyons que les connexions HTTP se font bien, et nous sommes donc confiants sur la mise en production.

D'autres types de m√©triques sont aussi accessibles via GitLab, afin de prendre des d√©cisions et voir la productivit√© de l'√©quipe.

Par exemple, lors du pr√©c√©dent chapitre, vous avez d√©ploy√© un environnement Canary afin d'analyser le comportement de l'application. Pour voir comment cet environnement se comporte et si celui-ci est viable, allez dans le menu **Operations**, puis **Environments**. Vous devriez voir votre nouvel environnement `canary` et voir les m√©triques associ√©es :

![Les m√©triques associ√©es √† Canary](https://user.oc-static.com/upload/2019/05/23/15586227065086_canary.png)

Pour voir la performance et la productivit√© de l'√©quipe, GitLab int√®gre aussi des m√©triques concernant le code, les issues, ou encore le temps d'ex√©cution des tests. Ces diff√©rentes m√©triques sont disponibles dans le menu Project, sous-menu Cycle Analytics.

Les m√©triques les plus int√©ressantes sont celles qui fournissent des indicateurs sur la v√©locit√© et la productivit√© de l'√©quipe. Par exemple, il est possible de voir **le temps entre la cr√©ation d'une issue et sa r√©solution** dans la rubrique Review.

Il est possible de voir aussi le temps de d√©ploiement sur les diff√©rents environnements. Plus cette valeur est petite, plus il est facile de d√©ployer sur les environnements. Par exemple, dans l'exemple ci-dessous, le temps de d√©ploiement sur l'environnement de Staging est de 3 minutes en moyenne. Avec un temps de d√©ploiement aussi court, il est facile de d√©ployer une correction en production assez rapidement.

![M√©trique sur le temps de d√©ploiement](https://user.oc-static.com/upload/2019/05/23/1558622961915_metrics-staging.png)

Il y a aussi d'autres m√©triques qui existent, concernant le code. Par exemple, vous pouvez voir le nombre de commits, ainsi que les diff√©rents contributeurs dans le menu Repository, sous-menu Contributors.

![M√©triques sur les contributeurs](https://user.oc-static.com/upload/2019/05/23/15586230184054_commiters.png)

Il est aussi int√©ressant de voir le nombre de commits par jours, pour √©valuer le temps de travail de chaque d√©veloppeur. Cette m√©trique est disponible dans le m√™me menu, sous-menu Charts.

### Mettez en place des notifications Slack

La derni√®re √©tape est l'√©tape de **feedback rapide**. Cette √©tape est celle qui va nous permettre de faire le lien entre la **production** (ops), et les **d√©veloppeurs** (dev). C'est une √©tape qui donne de la visibilit√© aux d√©veloppeurs sur des probl√®mes qu'il peut y avoir en production. **Plus rapide est la d√©tection des probl√®mes, plus rapide est leur correction**. 

Cette √©tape est le lien final qui permet d'avoir notre am√©lioration continue durant tout le cycle de vie de l'application. GitLab permet l'int√©gration avec beaucoup d'applications tierces. L'int√©gration la plus simple est l'int√©gration email. Afin d'int√©grer GitLab avec l'email, allez dans le menu Settings, sous-menu Integrations. Dans ce menu, choisissez "Email on push". Sur le prochain √©cran, cochez la case Active, renseignez votre mail et cliquez sur "Test settings and save changes".

![Activez les notifications](https://user.oc-static.com/upload/2019/05/23/15586230769625_integration-mail.png)

Vous allez maintenant √™tre alert√© des diff√©rents commits qu'il pourrait y avoir sur le contr√¥le de code source. Mais l'int√©gration n'est que partielle avec l'email. Le mieux est d'int√©grer un outil comme Slack qui prendra toutes les notifications de GitLab, et les affichera dans un channel d√©di√© √† votre application. Pour int√©grer Slack, il suffit d'aller dans le menu Integrations, et de choisir Slack Notifications.

![Activez les notifications Slack](https://user.oc-static.com/upload/2019/05/23/15586231586449_integration-slack.png)

De cette page, vous allez √™tre invit√© √† cr√©er un webhook Slack afin de l'int√©grer dans votre repository GitLab.

Choisissez un channel d√©di√© √† votre application afin de recevoir tous les messages associ√©s. Attention, les messages sont nombreux. Je vous conseille de ne pas l'ajouter dans le channel G√©n√©ral.

![Configurez le channel Slack o√π recevoir les notifications](https://user.oc-static.com/upload/2019/05/23/15586232034197_slack-integration.png)

Une fois le webhook cr√©√©, copiez l'URL d√©livr√©e par Slack afin de la coller dans GitLab.

Lorsque l'int√©gration avec Slack est finie, vous recevrez tous les messages des √©v√©nements GitLab dans le channel associ√©.

![Slack avec vos notifications de GitLab](https://user.oc-static.com/upload/2019/05/23/15586232703011_slack.png)


> Nous avons donc rempli les deux derni√®res √©tapes de la livraison continue : 
> 1. ‚úÖLa codification de l'infrastructure avec l'**Infrastructure-as-Code**.
> 2. ‚úÖLe **d√©ploiement** de votre application.
> 3. ‚úÖLe **test** de votre application en environnement de test.
> 4. ‚úÖLa **supervision** de l'application.
> 5. ‚úÖLa mise en place de **notifications** d'alerte.

---

## Annexes

- [Mettez en place l'int√©gration et la livraison continues avec la d√©marche DevOps - OpenClassroom](https://openclassrooms.com/fr/courses/2035736-mettez-en-place-lintegration-et-la-livraison-continues-avec-la-demarche-devops) ;
- [Devenir expert / experte en DevOps - LinkedIn Learning ](https://www.linkedin.com/learning/paths/devenir-expert-experte-en-devops?u=56745737) ;
- [Continuous integration vs. continuous delivery vs. continuous deployment - Atlasian](https://www.atlassian.com/continuous-delivery/principles/continuous-integration-vs-delivery-vs-deployment)
- [DevOps In 5 Minutes | What Is DevOps? - Simplilearn (Youtube)](https://www.youtube.com/watch?v=Xrgk023l4lI)

***

_R√©alis√© en Markdown avec [Dillinger](https://dillinger.io/) - Par [Nicolas Barbarisi](https://www.nicolas-barbarisi.com)_